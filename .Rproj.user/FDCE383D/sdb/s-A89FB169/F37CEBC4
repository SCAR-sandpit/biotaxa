{
    "collab_server" : "",
    "contents" : "## Use the code in Taxon_curves.R for initial data treatments\n## Note: update/clean the dataset before finalizing the use of the script\n\nsetwd(\"/Users/hhsieh/Documents/ANTABIS/RASp/RAS species list/Three Bigs\")\ndata <- read.csv(\"ThreeBigs_n_2.0.csv\", sep = \",\", header = T, row.names = NULL)\ndata_s <- subset(data, Match.type != \"\")\ndata_s <- subset(data_s, Kingdom !=\"\" & Kingdom != \"P. Micheli ex Haller\")\nlibrary(stringr)\n\nAuthority_year <- function(Authority_accepted) {\n  regexp <- \"[[:digit:]]+\"\n  return(str_extract(Authority_accepted, regexp))\n}\n\nAuthority <- as.character(data_s$Authority_accepted)\n\nyear <- unlist(lapply(Authority, Authority_year))\ndata_m <- data.frame(data_s, year)\ndata_m <- subset(data_m, year!= \"\")\n\nlibrary(data.table)\n\ndata_m <- data.frame(data_s, year)\ndata_m <- subset(data_m, year!= \"\")[,c(16,19:24,44)]\ncolnames(data_m) <- c(\"AphiaIDs\", \"Kingdoms\", \"Phyla\", \"Classes\", \"Orders\", \"Families\", \"Genera\", \"year\")\n\ntaxaaccum <- function(taxa, rank) {\n  df <- subset(data_m, Kingdoms == taxa | Phyla == taxa | Classes == taxa |                 Orders == taxa | Families == taxa | Genera == taxa)\n  dt = as.data.table(unique(df))\n  setkey(dt, \"year\")\n  if (rank == \"Phylum\") {\n    dt[, id := as.numeric(factor(Phyla, levels = unique(Phyla)))]\n    ranklabel = \"phyla\"\n  } else if (rank == \"Class\") {\n    dt[, id := as.numeric(factor(Classes, levels = unique(Classes)))]\n    ranklabel = \"classes\"\n  } else if (rank == \"Order\") {\n    dt[, id := as.numeric(factor(Orders, levels = unique(Orders)))]\n    ranklabel = \"orders\"\n  } else if (rank == \"Family\") {\n    dt[, id := as.numeric(factor(Families, levels = unique(Families)))]\n    ranklabel = \"families\"\n  } else if (rank == \"Genus\") {\n    dt[, id := as.numeric(factor(Genera, levels = unique(Genera)))]\n    ranklabel = \"genera\"\n  } else if (rank == \"Species\") {\n    dt[, id := as.numeric(factor(AphiaIDs, levels = unique(AphiaIDs)))]\n    ranklabel = \"species\"\n  }\n  setkey(dt, \"year\", \"id\")\n  dt.out <- dt[J(unique(year)), mult = \"last\"]#[, Phylum := NULL]\n  dt.out[, id := cummax(id)]\n  numtaxa <- cummax(as.numeric(factor(dt$id)))\n  taxa_dt <- aggregate(numtaxa, list(year = dt$year), max )\n  colnames(taxa_dt) <- c(\"year\", \"taxa count\")\n  plot(taxa_dt$year, taxa_dt$`taxa count`, xlab = \"Year\", ylab = paste(\"Number of\", ranklabel, sep = \" \"))\n  title(taxa)\n}\n\n# statistical models\ntaxamodel <- function(taxa, rank, method) {\n  df <- subset(data_m, Kingdoms == taxa | Phyla == taxa | Classes == taxa |\nOrders == taxa | Families == taxa | Genera == taxa)\n  dt = as.data.table(unique(df))\n  setkey(dt, \"year\")\n  if(rank == \"Phylum\") {\n    dt[, id := as.numeric(factor(Phyla, levels = unique(Phyla)))]\n    ranklabel = \"phyla\"\n  } else if(rank == \"Class\") {\n    dt[, id := as.numeric(factor(Classes, levels = unique(Classes)))]\n    ranklabel = \"classes\"\n  } else if(rank == \"Order\") {\n    dt[, id := as.numeric(factor(Orders, levels = unique(Orders)))]\n    ranklabel = \"orders\"\n  } else if(rank == \"Family\") {\n    dt[, id := as.numeric(factor(Families, levels = unique(Families)))]\n    ranklabel = \"families\"\n  } else if(rank == \"Genus\") {\n    dt[, id := as.numeric(factor(Genera, levels = unique(Genera)))]\n    ranklabel = \"genera\"\n  } else if(rank == \"Species\") {\n    dt[, id := as.numeric(factor(AphiaIDs, levels = unique(AphiaIDs)))]\n    ranklabel = \"species\"\n  }\n  setkey(dt, \"year\", \"id\")\n  dt.out <- dt[J(unique(year)), mult = \"last\"]#[, Phylum := NULL]\n  dt.out[, id := cummax(id)]\n  numtaxa <- cummax(as.numeric(factor(dt$id)))\n  taxa_dt <- aggregate(numtaxa, list(year = dt$year), max )\n  colnames(taxa_dt) <- c(\"year\", \"taxa count\")\n  plot(taxa_dt$year, taxa_dt$`taxa count`, xlab = \"Year\", ylab = paste(\"Number of\", ranklabel, sep = \" \"), ylim = c(0, max(taxa_dt$\"taxa count\")*1.35))\n  title(taxa)\n\n  if(method == \"logistic\") {\n    N_obs <- taxa_dt$'taxa count'\n    times <- as.numeric(taxa_dt$year)\n\n    SS<-getInitial(N_obs~SSlogis(times,alpha,xmid,scale),data=data.frame(N_obs=N_obs,times=times))\n    K_start <- SS[\"alpha\"]\n    R_start <- 1/SS[\"scale\"]\n    N0_start <- SS[\"alpha\"]/(exp(SS[\"xmid\"]/SS[\"scale\"])) + 1\n    #return(summary(SS))\n\n    log_formula<-formula(N_obs ~ K * N0 * exp(R * times) / (K + N0 * (exp(R * times) - 1)))\n    m<-nls(log_formula,start = list(K = K_start, R = R_start, N0 = N0_start))\n    #estimated parameters\n    #summary(m)\n\n    corr_coef <- cor(N_obs,predict(m))\n    #return(corr_coef)\n    lines(times,predict(m),col=\"red\",lty=2,lwd=2)\n    n = length(times)\n\n    ## add model predictions\n    K = summary(m)$coefficient[1]\n    R = summary(m)$coefficient[2]\n    N0 = summary(m)$coefficient[3]\n\n    ## add variances - first, find standard errors\n    K_se = summary(m)$coefficients[4]\n    R_se = summary(m)$coefficients[5]\n    N0_se = summary(m)$coefficients[6]\n\n    ## compute standard deviations\n    K_sd = K_se * sqrt(n)\n    R_sd = R_se * sqrt(n)\n    N0_sd = N0_se * sqrt(n)\n\n    # compute upper bounds of model prediction\n    UP = (K + K_sd) * (N0 + N0_sd) * exp((R + R_sd)*times)/((K + K_sd)+(N0 + N0_sd)*(exp((R + R_sd)*times)-1))\n    lines(times, UP, col = 'red', lty = \"dashed\")\n    LW = (K - K_sd) * (N0 - N0_sd) * exp((R - R_sd)*times)/((K - K_sd)+(N0 - N0_sd)*(exp((R - R_sd)*times)-1))\n    lines(times, LW, col ='red', lty = 'dashed')\n    return('correlation coefficient' = corr_coef)\n  } else if(method == \"Michaelis-Menten\") {\n\n    # refer to this page https://stackoverflow.com/questions/27547548/solving-error-message-step-halving-factor-reduced-below-minimum-in-nls-step-a\n\n    N_obs <- taxa_dt$'taxa count'\n    times <- as.numeric(taxa_dt$year)\n\n    MM <- getInitial(N_obs~SSmicmen(times, Vm, K),data=data.frame(N_obs=N_obs,times=times))\n\n    Vm_start <- MM[\"Vm\"]\n    K_start <- MM[\"K\"]\n\n    #model <- nls(N_obs ~ SSmicmen(N_obs, Vm, K), data = dd)\n    model <- nls(N_obs ~ Vm * times / (K + times), start = list(Vm = Vm_start, K = K_start))\n    #return(summary(model))\n\n    corr_coef <- cor(N_obs, predict(model))\n    #return(corr_coef)\n    lines(times,predict(model),col=\"red\",lty=2,lwd=2)\n    n = length(times)\n    ## add model predictions\n    a = summary(model)$coefficient[1]\n    b = summary(model)$coefficient[2]\n    lines(times,predict(model),col=\"red\",lty=2,lwd=2)\n    ## add variances - first, find standard errors\n    a_se = summary(model)$coefficients[3]\n    b_se = summary(model)$coefficients[4]\n    ## compute standard deviations\n    a_sd = a_se * sqrt(n)\n    b_sd = b_se * sqrt(n)\n    # compute upper bounds of model prediction\n    UP = (a + a_sd) * times / (b - b_sd + times)\n    lines(times, UP, col = 'red', lty = \"dashed\")\n    LW = (a - a_sd) * times / (b + b_sd + times)\n    lines(times, LW, col ='red', lty = 'dashed')\n    #return(summary(model))\n    return('correlation coefficient' = corr_coef)\n  }\n}\n\nmodelcomparison <- function(taxa, rank) {\n  #yield one plot with two prediction curves, respectively, based on the two models\n  #deliver correlation coefficients of the two models\n  #maybe use ggplot2\n  df <- subset(data_m, Kingdoms == taxa | Phyla == taxa | Classes == taxa | Orders == taxa | Families == taxa | Genera == taxa)\n  dt = as.data.table(unique(df))\n  setkey(dt, \"year\")\n  if(rank == \"Phylum\") {\n    dt[, id := as.numeric(factor(Phyla, levels = unique(Phyla)))]\n    ranklabel = \"phyla\"\n  } else if(rank == \"Class\") {\n    dt[, id := as.numeric(factor(Classes, levels = unique(Classes)))]\n    ranklabel = \"classes\"\n  } else if(rank == \"Order\") {\n    dt[, id := as.numeric(factor(Orders, levels = unique(Orders)))]\n    ranklabel = \"orders\"\n  } else if(rank == \"Family\") {\n    dt[, id := as.numeric(factor(Families, levels = unique(Families)))]\n    ranklabel = \"families\"\n  } else if(rank == \"Genus\") {\n    dt[, id := as.numeric(factor(Genera, levels = unique(Genera)))]\n    ranklabel = \"genera\"\n  } else if(rank == \"Species\") {\n    dt[, id := as.numeric(factor(AphiaIDs, levels = unique(AphiaIDs)))]\n    ranklabel = \"species\"\n  }\n  setkey(dt, \"year\", \"id\")\n  dt.out <- dt[J(unique(year)), mult = \"last\"]#[, Phylum := NULL]\n  dt.out[, id := cummax(id)]\n  numtaxa <- cummax(as.numeric(factor(dt$id)))\n  taxa_dt <- aggregate(numtaxa, list(year = dt$year), max )\n  colnames(taxa_dt) <- c(\"year\", \"taxa count\")\n  plot(taxa_dt$year, taxa_dt$`taxa count`, xlab = \"Year\", ylab = paste(\"Number of\", ranklabel, sep = \" \"), ylim = c(0, max(taxa_dt$\"taxa count\")*1.35))\n  title(taxa)\n\n  N_obs <- taxa_dt$'taxa count'\n  times <- as.numeric(taxa_dt$year)\n\n  SS<-getInitial(N_obs~SSlogis(times,alpha,xmid,scale),data=data.frame(N_obs=N_obs,times=times))\n  K_start <- SS[\"alpha\"]\n  R_start <- 1/SS[\"scale\"]\n  N0_start <- SS[\"alpha\"]/(exp(SS[\"xmid\"]/SS[\"scale\"])) + 1\n\n  log_formula<-formula(N_obs ~ K * N0 * exp(R * times) / (K + N0 * (exp(R * times) - 1)))\n  m<-nls(log_formula,start = list(K = K_start, R = R_start, N0 = N0_start))\n\n  corr_coef_ss <- cor(N_obs,predict(m))\n\n  lines(times,predict(m),col=\"red\",lty=2,lwd=2)\n  n = length(times)\n\n  ## add model predictions\n  K = summary(m)$coefficient[1]\n  R = summary(m)$coefficient[2]\n  N0 = summary(m)$coefficient[3]\n\n  ## add variances - first, find standard errors\n  K_se = summary(m)$coefficients[4]\n  R_se = summary(m)$coefficients[5]\n  N0_se = summary(m)$coefficients[6]\n\n  ## compute standard deviations\n  K_sd = K_se * sqrt(n)\n  R_sd = R_se * sqrt(n)\n  N0_sd = N0_se * sqrt(n)\n\n  # compute upper bounds of model prediction\n  UP = (K + K_sd) * (N0 + N0_sd) * exp((R + R_sd)*times)/((K + K_sd)+(N0 + N0_sd)*(exp((R + R_sd)*times)-1))\n  lines(times, UP, col = 'red', lty = \"dashed\")\n  LW = (K - K_sd) * (N0 - N0_sd) * exp((R - R_sd)*times)/((K - K_sd)+(N0 - N0_sd)*(exp((R - R_sd)*times)-1))\n  lines(times, LW, col ='red', lty = 'dashed')\n\n  ## add a M-M model\n  MM <- getInitial(N_obs~SSmicmen(times, Vm, K),data=data.frame(N_obs=N_obs,times=times))\n\n  Vm_start <- MM[\"Vm\"]\n  K_start <- MM[\"K\"]\n\n  #model <- nls(N_obs ~ SSmicmen(N_obs, Vm, K), data = dd)\n  model <- nls(N_obs ~ Vm * times / (K + times), start = list(Vm = Vm_start, K = K_start))\n  #return(summary(model))\n\n  corr_coef_mm <- cor(N_obs, predict(model))\n  #return(corr_coef)\n  lines(times,predict(model),col=\"blue\",lty=2,lwd=2)\n\n  n = length(times)\n  ## add model predictions\n  a = summary(model)$coefficient[1]\n  b = summary(model)$coefficient[2]\n\n  ## add variances - first, find standard errors\n  a_se = summary(model)$coefficients[3]\n  b_se = summary(model)$coefficients[4]\n  ## compute standard deviations\n  a_sd = a_se * sqrt(n)\n  b_sd = b_se * sqrt(n)\n  # compute upper bounds of model prediction\n  UP = (a + a_sd) * times / (b - b_sd + times)\n  lines(times, UP, col = 'blue', lty = \"dashed\")\n  LW = (a - a_sd) * times / (b + b_sd + times)\n  lines(times, LW, col ='blue', lty = 'dashed')\n\n  return(list('correlation coefficient of the logistic model' = corr_coef_ss, 'correlation coefficient of the Machaelis-Menten model' = corr_coef_mm))\n\n}\n\n\n",
    "created" : 1504613028797.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1347778459",
    "id" : "F37CEBC4",
    "lastKnownWriteTime" : 1504510740,
    "last_content_update" : 1504510740,
    "path" : "~/Documents/ANTABIS/RASp/RAS species list/Analyses/Taxon_app.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}